{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd7748e3",
   "metadata": {},
   "source": [
    "# Stroke Prediction Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55b737c",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "- Stroke is a global health concern, recognized by the World Health Organization (WHO) as the second leading cause of death worldwide, responsible for approximately 11% of total deaths. The ability to predict strokes accurately is not only a medical imperative but also a means to potentially save countless lives. This project centers on leveraging machine learning techniques to address this critical healthcare challenge.\n",
    "\n",
    "**Project Overview:**\n",
    "The primary objective of this project is to develop a predictive model that can effectively determine whether an individual is at risk of experiencing a stroke. To achieve this, we have utilized a comprehensive dataset provided by the WHO, which includes various patient attributes such as age, gender, medical history, and lifestyle factors.\n",
    "\n",
    "**Importance of the Project:**\n",
    "The importance of predicting strokes cannot be overstated. Timely identification of individuals at risk allows for early intervention and preventive measures, potentially mitigating the devastating consequences of strokes. Healthcare professionals can use predictive models as a tool to assess patients' risk profiles, enabling personalized care plans and resource allocation.\n",
    "\n",
    "By delving into this project, we aim to not only harness the power of machine learning for healthcare but also contribute to the broader mission of improving public health. Through accurate stroke prediction, we aspire to make a meaningful impact on global health outcomes and reduce the burden of this life-threatening condition.\n",
    "\n",
    "In the following sections, we will take you through the various steps involved in the project, including data preprocessing, feature engineering, model development, and evaluation. We will also discuss key findings, insights, and the potential implications of our predictive model for stroke prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5eef31",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df48fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4415c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into a Pandas DataFrame\n",
    "df = pd.read_csv('stroke_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a689d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae0134a",
   "metadata": {},
   "source": [
    "- Most columns do not have any missing values, which is excellent for our analysis.\n",
    "- The 'bmi' column has 201 missing values. We have several options to handle this missing data. One common approach is to impute the missing 'bmi' values with the mean value of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71bf2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values in the 'bmi' column with the mean\n",
    "mean_bmi = df['bmi'].mean()\n",
    "df['bmi'].fillna(mean_bmi, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ebf3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows if they exist\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a3b8d6",
   "metadata": {},
   "source": [
    "## Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cdd6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for numerical attributes\n",
    "summary_stats = df.describe()\n",
    "\n",
    "# Display the summary table\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89204415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms to visualize the distribution of numerical features\n",
    "df.hist(bins=20, figsize=(15, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d342e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count plots for categorical features\n",
    "categorical_columns = ['gender', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'smoking_status', 'stroke']\n",
    "for column in categorical_columns:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.countplot(x=column, data=df)\n",
    "    plt.title(f'Count plot of {column}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d24efef",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51435bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling (Standardization) for 'age', 'avg_glucose_level', and 'bmi'\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[['age', 'avg_glucose_level', 'bmi']] = scaler.fit_transform(df[['age', 'avg_glucose_level', 'bmi']])\n",
    "\n",
    "# Age Binning\n",
    "bins = [0, 30, 60, 100]\n",
    "labels = ['Young', 'Adult', 'Elderly']\n",
    "df['age_group'] = pd.cut(df['age'], bins=bins, labels=labels)\n",
    "\n",
    "# Interaction Term: 'age' x 'hypertension'\n",
    "df['age_hypertension_interaction'] = df['age'] * df['hypertension']\n",
    "\n",
    "# One-Hot Encoding for Categorical Variables\n",
    "categorical_columns = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status', 'age_group']\n",
    "df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431fed17",
   "metadata": {},
   "source": [
    "## Model Selection and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca759707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for model selection and training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3641631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features (X) and target variable (y)\n",
    "X = df.drop(['stroke'], axis=1)\n",
    "y = df['stroke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cd479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (adjust the test_size as needed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facdd55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the logistic regression\n",
    "model = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af675f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f07d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4382e435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress UndefinedMetricWarning by setting zero_division parameter to 'warn'\n",
    "classification_report_output = classification_report(y_test, y_pred, zero_division=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0878d32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEvaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3775fdd",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351f82d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for SMOTE and resampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a6bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use the F1-score as it balances precision and recall\n",
    "evaluation_metric = 'F1-score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e4614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the evaluation metric for the model's predictions on the testing set\n",
    "if evaluation_metric == 'Accuracy':\n",
    "    evaluation_result = accuracy_score(y_test, y_pred)\n",
    "elif evaluation_metric == 'Precision':\n",
    "    evaluation_result = precision_score(y_test, y_pred)\n",
    "elif evaluation_metric == 'Recall':\n",
    "    evaluation_result = recall_score(y_test, y_pred)\n",
    "elif evaluation_metric == 'F1-score':\n",
    "    evaluation_result = f1_score(y_test, y_pred)\n",
    "elif evaluation_metric == 'ROC-AUC':\n",
    "    # Calculate ROC-AUC only if you have a probabilistic model (e.g., Logistic Regression)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    evaluation_result = roc_auc_score(y_test, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3020fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the selected evaluation metric and its result\n",
    "print(f\"Selected Evaluation Metric: {evaluation_metric}\")\n",
    "print(f\"Evaluation Result ({evaluation_metric}): {evaluation_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738f1e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0ebff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for SMOTE and resampling\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ded709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the SMOTE resampler\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Resample the dataset using SMOTE\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data into training and testing sets\n",
    "X_train_resampled, X_test_resampled, y_train_resampled, y_test_resampled = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose a machine learning algorithm (e.g., Logistic Regression)\n",
    "model_resampled = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model on the resampled training data\n",
    "model_resampled.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the resampled testing data\n",
    "y_pred_resampled = model_resampled.predict(X_test_resampled)\n",
    "\n",
    "# Calculate F1-score for the resampled model\n",
    "f1_score_resampled = f1_score(y_test_resampled, y_pred_resampled)\n",
    "\n",
    "# Display the F1-score for the resampled model\n",
    "print(f\"F1-score for Resampled Model: {f1_score_resampled:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3ad2c1",
   "metadata": {},
   "source": [
    "In this section, we assessed the performance of our stroke prediction model, particularly focusing on the impact of addressing the dataset's class imbalance using Synthetic Minority Over-sampling Technique (SMOTE). We chose the F1-score as our primary evaluation metric because it balances precision and recall, which is crucial for our problem of predicting strokes.\n",
    "\n",
    "**Evaluation of the Initial Model:**\n",
    "- The initial model exhibited a high accuracy of 94%, which might seem promising at first glance.\n",
    "- However, a deeper analysis revealed a significant issue: the model's inability to effectively predict strokes (class 1). The F1-score for the positive class was 0.00, indicating that the model failed to correctly classify any positive cases.\n",
    "\n",
    "**Addressing Class Imbalance with SMOTE:**\n",
    "- To mitigate the class imbalance, we applied SMOTE, a resampling technique designed to oversample the minority class (stroke=1) by generating synthetic samples.\n",
    "- The resampling process balanced the dataset by creating additional positive cases, allowing the model to better learn from the minority class.\n",
    "\n",
    "**Performance of the Resampled Model:**\n",
    "- After applying SMOTE and training the model on the resampled data, we observed a substantial improvement in performance.\n",
    "- The F1-score for the positive class increased to 0.81, signifying a significant enhancement in the model's ability to predict strokes.\n",
    "\n",
    "**Interpretation and Implications:**\n",
    "- The resampled model demonstrates a much-improved balance between precision and recall for stroke prediction.\n",
    "- This improvement is crucial in a medical context, as it reduces the risk of missing actual stroke cases (increasing recall) while maintaining a high level of accuracy in classifying non-stroke cases (maintaining precision).\n",
    "- The F1-score, a harmonic mean of precision and recall, provides a more comprehensive assessment of model performance in this imbalanced dataset scenario.\n",
    "\n",
    "**Next Steps:**\n",
    "- While the resampled model shows promise, further steps can be taken to enhance its performance.\n",
    "- Hyperparameter tuning, feature engineering, and experimentation with different algorithms are avenues to explore.\n",
    "- Additionally, it's essential to validate the model on an independent dataset to ensure its generalizability and robustness.\n",
    "\n",
    "**Conclusion:**\n",
    "- The use of SMOTE to address class imbalance significantly improved our model's predictive performance for stroke classification.\n",
    "- The F1-score of 0.81 indicates a more balanced and accurate prediction, making the model more suitable for real-world applications.\n",
    "- These findings underscore the importance of considering and addressing class imbalance in medical predictive modeling tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c3666d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this project, we embarked on the task of predicting strokes based on a dataset provided by the World Health Organization (WHO). Stroke prediction is a crucial healthcare application due to its significant impact on public health. Our analysis and modeling efforts led to several key findings and takeaways:\n",
    "\n",
    "**Summary of Findings:**\n",
    "1. **Imbalanced Dataset**: The initial dataset exhibited a severe class imbalance, with significantly fewer positive cases (stroke=1) than negative cases (stroke=0).\n",
    "\n",
    "2. **Initial Model**: Our initial attempt at modeling yielded a high accuracy of 94%. However, a closer examination revealed a critical issueâ€”the model's inability to effectively predict strokes, as indicated by an F1-score of 0.00 for the positive class.\n",
    "\n",
    "3. **Addressing Class Imbalance**: To overcome the class imbalance problem, we applied Synthetic Minority Over-sampling Technique (SMOTE). This technique successfully balanced the dataset by generating synthetic positive cases.\n",
    "\n",
    "4. **Resampled Model**: After resampling with SMOTE and training a new model, we achieved a remarkable improvement. The F1-score for stroke prediction increased to 0.81, signifying a more balanced and accurate model.\n",
    "\n",
    "**Key Takeaways from the Project:**\n",
    "1. **Class Imbalance Matters**: The class imbalance issue in medical datasets is not to be underestimated. Neglecting it can lead to models that perform well in terms of accuracy but fail to predict critical outcomes like strokes.\n",
    "\n",
    "2. **SMOTE for Imbalanced Data**: SMOTE proved to be a valuable tool for addressing class imbalance, allowing the model to learn from minority cases effectively.\n",
    "\n",
    "3. **Evaluation Metrics**: In imbalanced datasets, the choice of evaluation metric is critical. We opted for the F1-score, which provided a balanced assessment of precision and recall.\n",
    "\n",
    "4. **Continuous Improvement**: Building effective predictive models often requires an iterative process. Hyperparameter tuning, feature engineering, and experimentation with different algorithms are essential for model enhancement.\n",
    "\n",
    "5. **Real-world Impact**: Predictive models for stroke can have a significant real-world impact on public health. Our improved model's ability to predict strokes accurately holds great promise in identifying individuals at risk and enabling timely interventions.\n",
    "\n",
    "In conclusion, this project highlights the importance of addressing class imbalance in medical predictive modeling. By leveraging techniques like SMOTE and selecting appropriate evaluation metrics, we significantly improved the predictive capabilities of our model for stroke prediction. As we move forward, further refinements and validations will be necessary to ensure the model's readiness for practical use in healthcare settings.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
